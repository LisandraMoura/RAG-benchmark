{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (0.39.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anyio<5,>=3.5.0->anthropic) (3.8)\n",
      "Requirement already satisfied: exceptiongroup in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
      "Requirement already satisfied: certifi in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.4)\n",
      "Requirement already satisfied: voyageai in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (0.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (3.10.5)\n",
      "Requirement already satisfied: aiolimiter in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (1.26.4)\n",
      "Requirement already satisfied: pillow in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (2.9.2)\n",
      "Requirement already satisfied: requests in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (2.32.3)\n",
      "Requirement already satisfied: tenacity in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (8.5.0)\n",
      "Requirement already satisfied: tokenizers>=0.14.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from voyageai) (0.20.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pydantic>=1.10.8->voyageai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pydantic>=1.10.8->voyageai) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pydantic>=1.10.8->voyageai) (4.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from tokenizers>=0.14.0->voyageai) (0.24.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (1.9.11)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from aiohttp->voyageai) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from requests->voyageai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from requests->voyageai) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from requests->voyageai) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from requests->voyageai) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.14.0->voyageai) (4.66.5)\n",
      "Requirement already satisfied: pandas in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib) (6.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/lisamenezes/anaconda3/envs/basic/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "## setup\n",
    "!pip install anthropic\n",
    "!pip install voyageai\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['VOYAGE_API_KEY'] = ('VOYAGE_API_KEY')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a Vector DB Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, name, api_key=None):\n",
    "        self.name = name\n",
    "        self.embeddings = []\n",
    "        self.metadata = []\n",
    "        self.query_cache = {}\n",
    "        self.db_path = f\"./data/{name}/vector_db.pkl\"\n",
    "\n",
    "    def load_data(self, data):\n",
    "        if self.embeddings and self.metadata:\n",
    "            print(\"Vector database is already loaded. Skipping data loading.\")\n",
    "            return\n",
    "        if os.path.exists(self.db_path):\n",
    "            print(\"Loading vector database from disk.\")\n",
    "            self.load_db()\n",
    "            return\n",
    "\n",
    "        texts = [f\"Heading: {item['chunk_heading']}\\n\\n Chunk Text: {item['text']}\" for item in data]\n",
    "        self._embed_and_store(texts, data)\n",
    "        self.save_db()\n",
    "        print(\"Vector database loaded and saved.\")\n",
    "\n",
    "    def _embed_and_store(self, texts, data):\n",
    "        batch_size = 128\n",
    "        result = []\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            response = openai.Embedding.create(\n",
    "                input=texts[i: i + batch_size],\n",
    "                # model=\"text-embedding-ada-002\"  # Modelo recomendado para embeddings7\n",
    "                model=\"text-embedding-3-small\"\n",
    "            )\n",
    "            embeddings = [res['embedding'] for res in response['data']]\n",
    "            result.extend(embeddings)\n",
    "\n",
    "        self.embeddings = result\n",
    "        self.metadata = data\n",
    "\n",
    "    def search(self, query, k=5, similarity_threshold=0.75):\n",
    "        # debug\n",
    "        print(\"[DEBUG] Searching for query:\", query)\n",
    "\n",
    "        if query in self.query_cache:\n",
    "            query_embedding = self.query_cache[query]\n",
    "            # degub\n",
    "            print(\"[DEBUG] Using cached embedding for query:\", query)\n",
    "        else:\n",
    "            response = openai.Embedding.create(\n",
    "                input=[query],\n",
    "                # model=\"text-embedding-ada-002\"\n",
    "                model=\"text-embedding-3-small\"\n",
    "            )\n",
    "            query_embedding = response['data'][0]['embedding']\n",
    "            self.query_cache[query] = query_embedding\n",
    "            # debug\n",
    "            print(\"[DEBUG] Generated new embedding for query:\", query)\n",
    "\n",
    "        if not self.embeddings:\n",
    "            raise ValueError(\"No data loaded in the vector database.\")\n",
    "\n",
    "        # Cálculo da similaridade utilizando produto escalar\n",
    "        similarities = np.dot(self.embeddings, query_embedding)\n",
    "        # debug\n",
    "        print(\"[DEBUG] Similarities calcualeted:\", similarities)\n",
    "        top_indices = np.argsort(similarities)[::-1]\n",
    "        top_examples = []\n",
    "\n",
    "        for idx in top_indices:\n",
    "            print(\"[DEBUG]\")\n",
    "            if similarities[idx] >= similarity_threshold:\n",
    "                example = {\n",
    "                    \"metadata\": self.metadata[idx],\n",
    "                    \"similarity\": similarities[idx],\n",
    "                }\n",
    "                top_examples.append(example)\n",
    "\n",
    "                if len(top_examples) >= k:\n",
    "                    break\n",
    "        self.save_db()\n",
    "        return top_examples\n",
    "\n",
    "    def save_db(self):\n",
    "        data = {\n",
    "            \"embeddings\": self.embeddings,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"query_cache\": json.dumps(self.query_cache),\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
    "        with open(self.db_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_db(self):\n",
    "        if not os.path.exists(self.db_path):\n",
    "            raise ValueError(\"Vector database file not found. Use load_data to create a new database.\")\n",
    "        with open(self.db_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.embeddings = data[\"embeddings\"]\n",
    "        self.metadata = data[\"metadata\"]\n",
    "        self.query_cache = json.loads(data[\"query_cache\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugchat import hugchat\n",
    "from hugchat.login import Login\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configurações de login\n",
    "EMAIL = \"hdsdosol@gmail.com\"\n",
    "PASSWD = \"Lisa2210@\"\n",
    "cookie_path_dir = \"./cookies/\"  # O diretório onde os cookies serão salvos\n",
    "\n",
    "# Login no HuggingFace\n",
    "sign = Login(EMAIL, PASSWD)\n",
    "cookies = sign.login(cookie_dir_path=cookie_path_dir, save_cookies=True)\n",
    "\n",
    "# Cria o ChatBot com cookies obtidos\n",
    "chatbot = hugchat.ChatBot(cookies=cookies.get_dict())\n",
    "\n",
    "# Função para chamar o modelo via HuggingChat\n",
    "def call_huggingchat(prompt, model_name, retries=3, delay=20):\n",
    "    models = chatbot.get_available_llm_models()\n",
    "    model_index = next((i for i, m in enumerate(models) if m.id == model_name), None)\n",
    "\n",
    "    if model_index is not None:\n",
    "        chatbot.switch_llm(model_index)\n",
    "        print(f\"Modelo '{model_name}' selecionado com sucesso!\")\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo '{model_name}' não encontrado entre os disponíveis.\")\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            chatbot.new_conversation(switch_to=True)\n",
    "            response = chatbot.chat(prompt)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na tentativa {attempt + 1}: {e}\")\n",
    "            if \"You are sending too many messages\" in str(e):\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return None\n",
    "\n",
    "# Carregar o documento do seu caminho específico\n",
    "with open('/home/lisamenezes/RAG-benchmark/data/fundamentos-all.json', 'r') as f:\n",
    "    fundamentos_data = json.load(f)\n",
    "\n",
    "def validate_data(data):\n",
    "    for i, item in enumerate(data):\n",
    "        if 'chunk_heading' not in item or not item['chunk_heading']:\n",
    "            print(f\"[DEBUG] Missing or empty 'chunk_heading' in item {i}: {item}\")\n",
    "        if 'text' not in item or not item['text']:\n",
    "            print(f\"[DEBUG] Missing or empty 'text' in item {i}: {item}\")\n",
    "        if 'context' not in item:\n",
    "            print(f\"[DEBUG] Missing 'context' field in item {i}, adding default value.\")\n",
    "            item['context'] = \"No context available.\"\n",
    "    return data\n",
    "\n",
    "# Inicializar o VectorDB com seus dados\n",
    "db = VectorDB(\"fundamentos\")\n",
    "db.load_data(fundamentos_data)\n",
    "\n",
    "def retrieve_base(query, db):\n",
    "    results = db.search(query, k=3)\n",
    "    context = \"\"\n",
    "    for result in results:\n",
    "        chunk = result['metadata']\n",
    "        context += f\"\\n{chunk['text']}\\n\"\n",
    "        print(context)\n",
    "        # print(\"Resultados da busca:\", results)\n",
    "    return results, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_base(query, db):\n",
    "    documents, context = retrieve_base(query, db)\n",
    "    prompt = f\"\"\"\n",
    "    Você é um assistente juridico que responde a seguinte pergunta: \n",
    "    <pergunta>\n",
    "    {query}\n",
    "    </pergunta>\n",
    "    Você tem acesso aos seguintes documentos, que devem fornecer contexto à medida que responde à consulta:\n",
    "    <contexto>\n",
    "    {context}\n",
    "    </contexto>\n",
    "    Por favor, permaneça fiel ao contexto subjacente e só se desvie dele se tiver 100% de certeza de que já sabe a resposta. \n",
    "    Responda à pergunta agora e evite fornecer preâmbulos como 'Aqui está a resposta', etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = call_huggingchat(prompt, model_name=\"meta-llama/Meta-Llama-3.1-70B-Instruct\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto Recuperado:\n",
      "\n",
      "Art. 30 - § 1oAquele que tiver direito à posse provisória, mas não puder\n",
      "prestar a garantia exigida neste artigo, será excluído, mantendo-se os bens que lhe\n",
      "deviam caber sob a administração do curador, ou de outro herdeiro designado pelo juiz, e\n",
      "que preste essa garantia.\n",
      "\n",
      "Art. 30 - § 1oAquele que tiver direito à posse provisória, mas não puder\n",
      "prestar a garantia exigida neste artigo, será excluído, mantendo-se os bens que lhe\n",
      "deviam caber sob a administração do curador, ou de outro herdeiro designado pelo juiz, e\n",
      "que preste essa garantia.\n",
      "\n",
      "Art. 1.211. Quando mais de uma pessoa se disser possuidora, manter-se-á\n",
      "provisoriamente a que tiver a coisa, se não estiver manifesto que a obteve de alguma das\n",
      "outras por modo vicioso.\n",
      "\n",
      "Modelo 'meta-llama/Meta-Llama-3.1-70B-Instruct' selecionado com sucesso!\n",
      "\n",
      "Texto Gerado pelo LLM:\n",
      "A posse provisória é um instituto jurídico que garante a manutenção da posse de uma pessoa sobre um bem ou direito até que a questão seja definitivamente resolvida pelo juiz. De acordo com o Art. 1.211 do Código Civil, quando mais de uma pessoa se disser possuidora de um bem, a posse será mantida provisoriamente pela pessoa que está na posse atual da coisa, a menos que seja manifesto que a pessoa obteve a coisa de uma das outras por meio de um método vicioso.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Exemplo de uso para realizar uma consulta e gerar uma resposta\n",
    "start = time.time()\n",
    "query = \"posse provisória\"\n",
    "results, context = retrieve_base(query, db)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Contexto Recuperado:\")\n",
    "print(context)\n",
    "\n",
    "print(\"Tempo de execução\")\n",
    "print(end-start)\n",
    "# Gerar o texto usando o LLM\n",
    "response = answer_query_base(query, db)\n",
    "\n",
    "print(\"\\nTexto Gerado pelo LLM:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_rag_output(context, chunk_heading, text, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Avalia se a saída do RAG está alinhada com o termo de busca e o texto de referência.\n",
    "\n",
    "    Args:\n",
    "        context (str): O contexto recuperado pelo RAG.\n",
    "        chunk_heading (str): O termo de busca.\n",
    "        text (str): O texto de referência correto do chunk.\n",
    "        model (str): O modelo GPT a ser usado (padrão: gpt-4).\n",
    "\n",
    "    Returns:\n",
    "        str: Resposta do GPT com o julgamento.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Você é um modelo treinado para avaliar respostas de sistemas baseados em Recuperação-Aumentada por Geração (RAG).\n",
    "    Sua tarefa é julgar se o \"contexto\" recuperado pelo RAG está alinhado com o \"termo de busca\" (chunk_heading) e com o \"texto de referência correto\" (text).\n",
    "\n",
    "    Aqui estão as informações fornecidas:\n",
    "    - Contexto recuperado no RAG (3 contextos):\n",
    "    {context}\n",
    "\n",
    "    - Termo de busca:\n",
    "    {chunk_heading}\n",
    "\n",
    "    - Texto de referência correto:\n",
    "    {text}\n",
    "\n",
    "    Julgue se ao menos 1 dos 3 contextos é igual ao texto de referência, isso significará que o contexto está adequado ao termo de busca.\n",
    "    Responda com \"adequado\" ou \"inadequado\".\n",
    "    Não adicione nenhum comentário extra.\n",
    "    # Formato da saída:\n",
    "    Ex.:'adequado'\n",
    "    Ex.:'inadequado'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao avaliar: {str(e)}\"\n",
    "\n",
    "\n",
    "# Interação com o JSON de teste\n",
    "def evaluate_test_data(test_data, db):\n",
    "    \"\"\"\n",
    "    Itera sobre um JSON de teste e avalia cada entrada usando o GPT como julgador.\n",
    "\n",
    "    Args:\n",
    "        test_data (list): Lista de entradas do JSON de teste.\n",
    "        db (VectorDB): Instância do banco de vetores carregado.\n",
    "\n",
    "    Returns:\n",
    "        list: Resultados das avaliações.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for item in tqdm(test_data, desc=\"LLM as a judge: \", unit=\"entrada\"):\n",
    "        chunk_heading = item[\"chunk_heading\"]\n",
    "        text = item[\"text\"]\n",
    "        _, context = retrieve_base(chunk_heading, db)\n",
    "\n",
    "        evaluation = evaluate_rag_output(context, chunk_heading, text)\n",
    "        results.append({\n",
    "            \"chunk_heading\": chunk_heading,\n",
    "            \"context\": context,\n",
    "            \"text\": text,\n",
    "            \"evaluation\": evaluation\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Carregar dados de teste e avaliar\n",
    "with open('/home/lisamenezes/RAG-benchmark/data/fundamentos-test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "evaluation_results = evaluate_test_data(test_data, db)\n",
    "\n",
    "# Salvar os resultados para análise posterior\n",
    "with open('/home/lisamenezes/RAG-benchmark/results/3_small.json', 'w') as f:\n",
    "    json.dump(evaluation_results, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar os resultados de avaliação\n",
    "with open('/home/lisamenezes/RAG-benchmark/results/3_small.json', 'r') as f:\n",
    "    evaluation_results = json.load(f)\n",
    "\n",
    "# Contar as avaliações adequadas e inadequadas\n",
    "evaluation_counts = {\"adequado\": 0, \"inadequado\": 0}\n",
    "for result in evaluation_results:\n",
    "    evaluation = result[\"evaluation\"].lower()  # Garantir consistência de casos\n",
    "    if evaluation in evaluation_counts:\n",
    "        evaluation_counts[evaluation] += 1\n",
    "\n",
    "# Calcular a porcentagem de adequados\n",
    "total = sum(evaluation_counts.values())\n",
    "percentage_adequados = (evaluation_counts[\"adequado\"] / total) * 100 if total > 0 else 0\n",
    "\n",
    "# Criar o gráfico\n",
    "labels = list(evaluation_counts.keys())\n",
    "sizes = list(evaluation_counts.values())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, sizes)\n",
    "plt.title(\"Distribuição das Avaliações (Adequado vs Inadequado)\")\n",
    "plt.xlabel(\"Tipo de Avaliação\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.xticks(labels)\n",
    "\n",
    "# Mostrar a porcentagem de adequados no console\n",
    "print(f\"Porcentagem de avaliações adequadas: {percentage_adequados:.2f}%\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
